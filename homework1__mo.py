# -*- coding: utf-8 -*-
"""homework1_ MO.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DRmezhSUHDnGLoVUPIr7YSKt64G5OGkx
"""

from google.colab import drive
drive.mount('/content/drive')

cd drive/My\ Drive

cd Colab\ Notebooks

from google.colab import files
uploaded = files.upload()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

housing_df = pd.read_csv('housing.csv')
housing_df

# сначала проверяют данные

df = pd.DataFrame(housing_df)
df.notnull()

housing_df.isna().sum() # есть ли пропуски

housing_df.isna().sum().sum() # общее кол-во пропусков

housing_df.info() # информация

housing_df.head()

housing_df.describe() # описывает характеристики

# классическая регрессия

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

housing_df = pd.read_csv('housing.csv')

housing_df.head() # посмотреть кореляцию показывает, есть ли скрытая связь

housing_df.drop('MEDV', axis=1) #удалить из Х колонку

housing_df.MEDV # это У или можно housing_df.['MEDV']

X_train, X_test, y_train, y_test = train_test_split(housing_df.drop('MEDV',axis=1), housing_df['MEDV'], test_size=0.25, random_state=42) # разделяет, чтобы разделение было одинаково random_state

X_train # посмотреть результат

X_train.shape # размер выборки

reg = LinearRegression()

reg.fit(X_train, y_train) # fit обучить регрессию

pred = reg.predict(X_test) # предсказать модель
pred

y_test.describe() # структура

y_test # на сколько ошибается

print(mean_squared_error(y_test,pred, squared = True))  # показвает ошибку У, среднеквадратичное отклонение

plt.figure(figsize=(20,9))
plt.plot(y_test.values, "blue",linewidth=5, label='Реальные значения')
plt.plot(pred, "red",linewidth=5, label='Предсказание')
plt.legend(loc='best')
plt.title("График пример")
plt.grid(True)
plt.show()

# деревья

from sklearn import tree
clf = tree.DecisionTreeRegressor()

clf = clf.fit(X_train, y_train)

pred_clf = clf.predict(X_test)

import graphviz 
dot_data = tree.export_graphviz(clf, out_file=None) 
graph = graphviz.Source(dot_data) 
graph.render("smpl")

dot_data = tree.export_graphviz(clf, out_file=None, 
                      feature_names=housing_df.drop('MEDV',axis=1).columns,  
                      class_names=housing_df.MEDV,  
                      filled=True, rounded=True,  
                      special_characters=True)  
graph = graphviz.Source(dot_data)  
graph

frame = { 'FeatureImportance': clf.feature_importances_, 'Feature': X_train.columns }
result = pd.DataFrame(frame)
result.sort_values(by='FeatureImportance', ascending=False).head(10)

# если удалить столбец RM, ошибка уменьшается незначительно

del housing_df['RM']

X_train, X_test, y_train, y_test = train_test_split(housing_df.drop('MEDV',axis=1), housing_df['MEDV'], test_size=0.25, random_state=42)

reg = LinearRegression().fit(X_train, y_train)
pred = reg.predict(X_test)

print(mean_squared_error(y_test, pred, squared=True))